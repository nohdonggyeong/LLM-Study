{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdWDDl9hY3D9",
        "outputId": "4e17ed90-d41c-4380-e535-697da56274c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas langchain_community langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY']='...'"
      ],
      "metadata": {
        "id": "xLRDGa6-Zbb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "try:\n",
        "  for model in genai.list_models():\n",
        "    print(model.name, model.supported_generation_methods)\n",
        "\n",
        "  print(\"Google GenAI API Key가 정상적으로 설정되어 있습니다.\")\n",
        "except: print(f\"API 키가 유효하지 않습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0-d2KsxDMIM",
        "outputId": "54b6968e-91fb-40e9-985d-aebaf00ff6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001 ['generateMessage', 'countMessageTokens']\n",
            "models/text-bison-001 ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
            "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro-vision-latest ['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-001-tuning ['generateContent', 'countTokens', 'createTunedModel']\n",
            "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0827 ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0924 ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-pro-exp-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-04-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-04-17-thinking ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
            "models/embedding-001 ['embedContent']\n",
            "models/text-embedding-004 ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens']\n",
            "models/gemini-embedding-exp ['embedContent', 'countTextTokens']\n",
            "models/aqa ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 ['predict']\n",
            "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
            "Google GenAI API Key가 정상적으로 설정되어 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"
      ],
      "metadata": {
        "id": "X-IDHfXtFCUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL의 가장 큰 특징은, Chain의 구성 요소를 파이프(|)로 연결하여 한 번에 실행한다는 점"
      ],
      "metadata": {
        "id": "aHyksVDnFZEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# topic에 대한 영어 농담을 하고, 이 것이 왜 농담인지 한국어로 설명하세요.\n",
        "fun_chat_template = ChatPromptTemplate([\n",
        "    ('user', \"\"\"Tell me an English joke about {topic}.\n",
        "      Then, explain in Korean why it is funny to English speakers.\n",
        "      Provide a Korean translation of the joke as well.\"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "QiHZoTBnFSBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL의 구조에서는 템플릿과 LLM 모델을 설정하고, 이를 하나로 묶어 체인을 묶어 생성함"
      ],
      "metadata": {
        "id": "3pFAGjO9GQgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joke = fun_chat_template | llm\n",
        "joke"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFjdYNwGGM3Y",
        "outputId": "f464ea3d-24d8-41e6-c0af-91c0f0053e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me an English joke about {topic}.\\n      Then, explain in Korean why it is funny to English speakers.\\n      Provide a Korean translation of the joke as well.'), additional_kwargs={})])\n",
              "| ChatGoogleGenerativeAI(model='models/gemini-1.5-flash-latest', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7d3774cdc990>, default_metadata=(), model_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후, 체인의 invoke를 실행하며 입력 포맷을 전달하면, 순서대로 체인이 실행되며 최종 결과로 연결됨. 입력 포맷은 Dict 형식으로 전달함"
      ],
      "metadata": {
        "id": "tzNaLhr-Gslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = joke.invoke({'topic': 'Bear'})\n",
        "# 매개변수가 1개일 때는 joke.invoke('eggs')도 가능\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDz6ya6gGhYo",
        "outputId": "d7abbace-7aae-4cf1-d66b-3096debfb15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='**Joke:**\\n\\nWhy don\\'t bears wear shoes?\\n\\nBecause they have bear feet!\\n\\n\\n**Explanation in Korean (한국어 설명):**\\n\\n이 농담이 영어권 사람들에게 웃긴 이유는 \"bear feet\" (베어 핏)이라는 말장난에 있습니다.  \"bear\"는 \"곰\"을 뜻하는 단어이지만,  \"bare\" (맨발의)와 발음이 거의 같습니다.  질문은 곰이 왜 신발을 신지 않는지 묻고 있지만, 답변은 곰이 \"bear feet\" 즉, \"맨발\"을 가지고 있기 때문이라고 말하며,  \"bear\"와 \"bare\"의 발음 유사성을 이용한 말장난으로 웃음을 유발합니다.  뜻밖의 단순한 대답과 어린아이들이 좋아할 만한 유치한 유머이기에 더욱 재미있게 느껴집니다.  영어권 문화에서는 이러한 말장난을 활용한 유머가 흔히 사용됩니다.\\n\\n\\n**Korean Translation (한국어 번역):**\\n\\n곰이 왜 신발을 신지 않을까요?\\n\\n곰 발바닥이 있으니까요! (곰 발이 있으니까요!)\\n\\n\\n**Note:**  The Korean translation uses \"곰 발바닥\" (bear paw/sole) or \"곰 발\" (bear foot) depending on preference. Both convey the intended meaning.  The humor is lost in translation unless the explanation is provided.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []}, id='run--9b18cc71-7260-40d2-8bfb-40e42e4cbc83-0', usage_metadata={'input_tokens': 35, 'output_tokens': 339, 'total_tokens': 374, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYLc43kG5Yp",
        "outputId": "e7301ac9-eaf2-45ae-b7cb-a07b1b5143ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Joke:**\n",
            "\n",
            "Why don't bears wear shoes?\n",
            "\n",
            "Because they have bear feet!\n",
            "\n",
            "\n",
            "**Explanation in Korean (한국어 설명):**\n",
            "\n",
            "이 농담이 영어권 사람들에게 웃긴 이유는 \"bear feet\" (베어 핏)이라는 말장난에 있습니다.  \"bear\"는 \"곰\"을 뜻하는 단어이지만,  \"bare\" (맨발의)와 발음이 거의 같습니다.  질문은 곰이 왜 신발을 신지 않는지 묻고 있지만, 답변은 곰이 \"bear feet\" 즉, \"맨발\"을 가지고 있기 때문이라고 말하며,  \"bear\"와 \"bare\"의 발음 유사성을 이용한 말장난으로 웃음을 유발합니다.  뜻밖의 단순한 대답과 어린아이들이 좋아할 만한 유치한 유머이기에 더욱 재미있게 느껴집니다.  영어권 문화에서는 이러한 말장난을 활용한 유머가 흔히 사용됩니다.\n",
            "\n",
            "\n",
            "**Korean Translation (한국어 번역):**\n",
            "\n",
            "곰이 왜 신발을 신지 않을까요?\n",
            "\n",
            "곰 발바닥이 있으니까요! (곰 발이 있으니까요!)\n",
            "\n",
            "\n",
            "**Note:**  The Korean translation uses \"곰 발바닥\" (bear paw/sole) or \"곰 발\" (bear foot) depending on preference. Both convey the intended meaning.  The humor is lost in translation unless the explanation is provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "매개변수가 2개인 Prompt-LLM Chain 생성하기"
      ],
      "metadata": {
        "id": "80TAwu_tHWSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        ('system', '당신은 재미있고 교훈적인 이야기를 씁니다.'),\n",
        "        ('user', '{A}와 {B}가 만났을 때의 대화를 써 주세요.')\n",
        "    ]\n",
        ")\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({'A': '햄릿', 'B': '슈퍼마리오'})\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziXBdLBzHQSe",
        "outputId": "7b876eba-e7bc-46ac-b65e-865d015a8ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "햄릿은 엘시노어 성의 으스스한 정원에서 한숨을 쉬고 있었다.  고민은 끝없이 이어지고, 오필리아의 죽음은 그의 마음을 찢어놓았다.  갑자기, 밝은 빨간 모자를 쓴 작은 인물이 그의 앞에 나타났다.\n",
            "\n",
            "\"맙소사! 난 슈퍼 마리오야! 길을 잃은 것 같아.\" 마리오는 손을 흔들며 말했다. 그의 목소리는 놀라울 정도로 밝고 쾌활했다.\n",
            "\n",
            "햄릿은 마리오를 눈앞에 두고 잠시 멍해졌다.  평소와는 다른 밝은 색깔의 인물, 그 작은 키와 활기찬 모습은 그의 우울한 분위기와는 너무나도 대조적이었다.\n",
            "\n",
            "\"당신은... 누구십니까?\" 햄릿은 겨우 입을 열었다. 그의 목소리는 낮고 침울했다.\n",
            "\n",
            "\"슈퍼 마리오라고!  구출해야 할 공주가 있거든. 근데... 여기가 어디지? 이런 으스스한 곳은 처음이야.\" 마리오는 주위를 두리번거리며 말했다.\n",
            "\n",
            "햄릿은 마리오의 말에 웃음이 터질 뻔했다.  공주?  그는 그의 고민과 비극적인 상황에 압도되어 있었는데, 이 작은 남자는 공주 구출에 대해 이야기하고 있었다.  그 차이가 웃기면서도 슬펐다.\n",
            "\n",
            "\"여기는 엘시노어 성이야.  나는 햄릿이고... 지금은 상당히 복잡한 상황에 처해있지.\" 햄릿은 그의 고민을 간략하게 설명하기 시작했다.  클라우디우스의 배신, 오필리아의 죽음, 복수에 대한 갈등...\n",
            "\n",
            "마리오는 햄릿의 이야기를 경청했다.  처음에는 눈을 크게 뜨고 놀라워했지만, 이야기가 진행될수록 그의 표정은 심각해졌다.  마리오는 비디오 게임 속의 세계와 달리, 햄릿의 세계가 얼마나 어둡고 고통스러운 곳인지 이해하기 시작했다.\n",
            "\n",
            "\"와... 그건 정말 힘든 일이네.  내가 공주를 구출하는 건 좀... 쉬운 편이지만, 네 상황은... 엄청 어려운 퍼즐 같아.\" 마리오는 잠시 생각에 잠겼다.  그리고는 햄릿에게 물었다. \"그런데, 너는 무엇을 해야 할 것 같아?\"\n",
            "\n",
            "햄릿은 마리오의 단순하지만 직설적인 질문에 잠시 생각했다.  마리오의 순수함과 긍정적인 에너지는 그의 어두운 마음에 작은 빛을 비추는 것 같았다.  그는 그의 고민을 다시 한번 정리하며, 마리오에게 그의 고뇌를 털어놓았다.\n",
            "\n",
            "\"모르겠어... 아직도 갈등 중이야.  하지만... 당신의 말이 나에게 용기를 주는 것 같아.  어쩌면... 내가 너무 깊이 빠져들었던 건 아닐까.\"\n",
            "\n",
            "마리오는 햄릿의 어깨를 두드렸다.  \"걱정 마!  모든 퍼즐에는 해결책이 있으니까!  힘내!\"\n",
            "\n",
            "마리오는 갑자기 사라졌다.  마치 버섯처럼 순간이동을 한 것 같았다.  햄릿은 혼자 남았지만, 마리오와의 만남은 그의 마음에 작은 희망의 불씨를 심어주었다.  그는 여전히 어두운 미래를 마주해야 했지만, 이제는 조금 더 용감하게, 조금 더 긍정적으로 앞으로 나아갈 수 있을 것 같았다.  마리오의 순수한 에너지는 햄릿에게 삶의 희망을 되찾아 주었다.  마치, 숨겨진 1-UP 버섯을 발견한 것처럼.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL의 체인에는 Parser를 추가할 수 있습니다.\n",
        "Parser는 출력 형식을 변환합니다."
      ],
      "metadata": {
        "id": "tlWGVMzuIB7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StrOutputParser: 출력 결과를 String 형식으로 변환합니다."
      ],
      "metadata": {
        "id": "LYTS1XFrIPtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "recipe_template=ChatPromptTemplate([\n",
        "    ('system', '당신은 전세계의 조리법을 아는 쉐프입니다.'),\n",
        "    ('user', '저는 {ingredient}를 이용한 환상적인 파인 다이닝을 만들고 싶습니다. 추천해주세요.')\n",
        "])"
      ],
      "metadata": {
        "id": "TaF3FpZwH0xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_chain = recipe_template | llm | StrOutputParser()\n",
        "response = recipe_chain.invoke({'ingredient': '연두부, 에너지바, 바나나'})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMhptASoIh9W",
        "outputId": "8f87ade2-b1a7-4734-9df4-024ad201771f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "연두부, 에너지바, 바나나를 활용한 파인 다이닝이라... 흥미로운 도전 과제군요! 재료들의 이질적인 조합을 고려하여, 각 재료의 장점을 극대화하고 조화롭게 어울리는 메뉴를 구성해 보겠습니다.  단순히 재료를 섞는 것이 아닌, 각 재료의 질감과 풍미를 극대화하고, 서로의 단점을 보완하는 데 초점을 맞추겠습니다.\n",
            "\n",
            "**메뉴명:  \"부드러움과 활력의 조화 - 연두부, 에너지바, 바나나의 세레나데\"**\n",
            "\n",
            "**코스 구성:**\n",
            "\n",
            "**1. Amuse-bouche (입가심): 바나나 에스푸마와 연두부 칩**\n",
            "\n",
            "* **바나나 에스푸마:** 잘 익은 바나나를 믹서에 갈아 거품기로 부드러운 에스푸마를 만듭니다.  약간의 레몬즙과 설탕을 더하여 상큼함과 단맛의 균형을 맞춥니다.\n",
            "* **연두부 칩:** 연두부를 얇게 펴서 오븐에 구워 바삭한 칩을 만듭니다.  소금과 후추로 간을 합니다.\n",
            "* **플레이팅:** 바나나 에스푸마를 작은 스푼으로 떠서 접시에 올리고, 연두부 칩을 곁들입니다.  에너지바에서 추출한 가루를 약간 뿌려 장식합니다 (아래 에너지바 활용 참고).\n",
            "\n",
            "**2. Appetizer (전채): 연두부 무스와 에너지바 크럼블을 곁들인 바나나 샐러드**\n",
            "\n",
            "* **연두부 무스:** 연두부를 믹서에 갈아 부드러운 무스를 만듭니다.  약간의 코코넛 밀크나 크림을 넣어 풍미를 더하고, 소금으로 간을 합니다.\n",
            "* **에너지바 크럼블:** 에너지바를 잘게 부수어 크럼블을 만듭니다.  견과류나 시리얼이 많이 들어간 에너지바를 선택하면 더욱 풍성한 식감을 제공합니다.\n",
            "* **바나나 샐러드:** 바나나를 얇게 썰고, 레몬즙을 뿌려 갈변을 방지합니다.  약간의 꿀이나 메이플 시럽을 뿌려 달콤함을 더합니다.\n",
            "* **플레이팅:** 연두부 무스를 접시에 바르고, 바나나 샐러드를 올립니다.  에너지바 크럼블을 뿌리고,  민트 잎이나 라임 제스트로 장식합니다.\n",
            "\n",
            "**3. Main Course (메인 코스): 구운 연두부와 에너지바 소스를 곁들인 바나나 퓨레**\n",
            "\n",
            "* **구운 연두부:** 연두부를 약간의 올리브 오일과 허브(로즈마리, 타임)를 뿌려 구워 향긋하고 부드러운 식감을 더합니다.\n",
            "* **에너지바 소스:** 에너지바를 블렌더에 갈아 부드러운 소스를 만듭니다.  우유나 크림을 넣어 농도를 조절하고,  약간의 발사믹 식초나 소금으로 맛을 냅니다.  에너지바의 종류에 따라 소스의 맛이 크게 달라집니다.  예를 들어, 초콜릿 에너지바는 진한 초콜릿 소스가 됩니다.\n",
            "* **바나나 퓨레:** 바나나를 으깨어 부드러운 퓨레를 만듭니다.\n",
            "* **플레이팅:** 구운 연두부를 접시에 올리고, 바나나 퓨레를 곁들입니다.  에너지바 소스를 드리즐 형태로 뿌리고,  견과류를 약간 뿌려 장식합니다.\n",
            "\n",
            "**에너지바 활용:**\n",
            "\n",
            "에너지바의 종류에 따라 메뉴의 맛이 크게 달라집니다.  견과류와 시리얼이 풍부한 에너지바를 선택하는 것이 좋습니다.  메뉴에 따라 에너지바를 그대로 사용하거나, 가루로 만들어 뿌리거나, 소스로 만들어 활용할 수 있습니다.  에너지바의 단맛과 견과류의 고소함이 연두부와 바나나의 부드러움과 잘 어울립니다.\n",
            "\n",
            "\n",
            "**주의사항:**\n",
            "\n",
            "* 에너지바의 재료와 맛을 고려하여 메뉴를 조정해야 합니다. 너무 단 에너지바는 메뉴 전체의 밸런스를 깨뜨릴 수 있습니다.\n",
            "* 연두부의 수분 함량을 고려하여 조리법을 조절해야 합니다.\n",
            "* 각 코스의 양을 적절하게 조절해야 합니다.\n",
            "\n",
            "\n",
            "이 메뉴는 연두부, 에너지바, 바나나의 독특한 조합을 통해 새로운 미식 경험을 제공할 것입니다.  각 재료의 특징을 살리고, 서로의 장점을 극대화하여 조화로운 맛을 창출하는 데 집중했습니다.  실제로 조리하면서 재료의 특성과 자신의 취향에 맞춰 조정하는 것을 잊지 마세요.  행복한 요리 시간 되시길 바랍니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "structured output"
      ],
      "metadata": {
        "id": "R4GL_fTzI3Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain의 Structured_Output 기능을 사용하면, 출력을 구조화할 수 있습니다."
      ],
      "metadata": {
        "id": "z-2HKZmHJJkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "# pydantic 연동\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "  name: str = Field(description=\"음식 이름\")\n",
        "  # name: 문자열, 설명은 \"음식 이름\"\n",
        "  difficulty: str = Field(description=\"만들기의 난이도\")\n",
        "\n",
        "  origin: str = Field(description=\"원산지\")\n",
        "  ingredients: list[str] = Field(description=\"재료\")\n",
        "  # ingredients: 문자열 리스트, 설명은 \"재료\"\n",
        "\n",
        "  instructions: list[str] = Field(description=\"조리법\")\n",
        "  tip: str = Field(description=\"조리 과정 팁\")"
      ],
      "metadata": {
        "id": "00o6P3XQItrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(Recipe)\n",
        "response = structured_llm.invoke(\"생강으로 만들 수 있는 요리 레시피 알려주세요.\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw70O9oGJ7eu",
        "outputId": "8f2005b6-596b-4a80-aa2f-7a5802282dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recipe(name='생강차', difficulty='easy', origin='한국', ingredients=['생강', '꿀', '물'], instructions=['생강을 얇게 썰어 물에 넣고 끓인다', '꿀을 넣고 졸인다'], tip='생강을 얇게 썰수록 매운맛이 덜하다')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runnables"
      ],
      "metadata": {
        "id": "EtkKX01bLGyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runnalbes는 LCEL의 기본 단위로, 입력을 받아 출력을 생성하는 기본 단위"
      ],
      "metadata": {
        "id": "7mf2oELjLIjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM, Prompt, Chain 등이 모두 Runnalbe 구조에 해당"
      ],
      "metadata": {
        "id": "pqjs4JemLNWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 흐름을 제어하는 특별한 Runnable인 RunnablePassthrough RunnableParallel을 이용해 체인 구성할 것"
      ],
      "metadata": {
        "id": "tE0vXAxxLUCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RunnablePassthrough는 체인의 직전 출력을 그대로 가져옴"
      ],
      "metadata": {
        "id": "04rY5ColQUyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "prompt1 = ChatPromptTemplate([\"{director}의 대표 작품은 무엇입니까?\"])\n",
        "chain1 = (\n",
        "    prompt1\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | {'answer': RunnablePassthrough()}\n",
        ")\n",
        "\n",
        "response = chain1.invoke(\"스티븐 스필버그\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izJHGryOKMA0",
        "outputId": "c6ff6c43-db7b-460d-9dee-75410f084b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': \"스티븐 스필버그의 대표작은 하나로 꼽기 어렵지만, 가장 흔히 언급되는 작품들은 다음과 같습니다:\\n\\n* **죠스 (Jaws, 1975):** 스필버그를 세계적인 거장으로 만든 작품으로, 서스펜스와 긴장감 넘치는 연출로 유명합니다.  상업적으로도 엄청난 성공을 거두었습니다.\\n\\n* **E.T. (1982):**  어린이와 외계인의 우정을 그린 감동적인 이야기로, 전세계적으로 큰 사랑을 받았습니다.  가족 영화의 걸작으로 꼽힙니다.\\n\\n* **쉰들러 리스트 (Schindler's List, 1993):** 홀로코스트를 다룬 흑백 영화로, 스필버그의 연출력과 메시지 전달 능력을 보여주는 깊이 있는 작품입니다.  비상업적인 성격에도 불구하고 큰 성공을 거두었으며, 그의 작품 중 가장 중요한 작품 중 하나로 평가받습니다.\\n\\n* **라이언 일병 구하기 (Saving Private Ryan, 1998):**  노르망디 상륙 작전을 배경으로 한 전쟁 영화로, 극도의 사실적인 묘사와 압도적인 전투 장면으로 유명합니다.  전쟁 영화의 걸작으로 평가받습니다.\\n\\n\\n어떤 작품을 가장 대표적인 작품으로 꼽을지는 개인의 취향과 기준에 따라 다를 수 있지만, 위 네 작품은 스필버그의 경력과 업적을 가장 잘 보여주는 대표적인 작품들입니다.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RunnableParallel은 서로 다른 체인을 병렬적으로 실행"
      ],
      "metadata": {
        "id": "8RIlvMlERT74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "prompt1 = ChatPromptTemplate([\"색깔을 하나 알려주세요, 색깔만 출력하세요.\"])\n",
        "prompt2 = ChatPromptTemplate([\"음식을 하나 알려주세요, 음식만 출력하세요.\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "chain2 = prompt2 | llm | StrOutputParser()\n",
        "\n",
        "chain3 = RunnableParallel(color = chain1, food = chain2)\n",
        "chain3.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ivtilM1Q1Ka",
        "outputId": "2ce83ba7-b6d3-4b34-f0f4-b1caba0fb698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'color': '파랑', 'food': '비빔밥'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM의 결과를 다음 LLM으로 연결해볼 것"
      ],
      "metadata": {
        "id": "tfKObHAPSPIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate([\"잭슨빌은 어느 나라의 도시입니까?\"])\n",
        "prompt2 = ChatPromptTemplate([\"{country}의 대표적인 인물 3명을 나열하세요. 인물의 이름만 출력하세요.\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "chain2 = (\n",
        "    {\"country\": chain1} | prompt2 | llm | StrOutputParser()\n",
        ")\n",
        "chain2.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FIKMCOj-Rtob",
        "outputId": "e11b9a16-622e-42b3-dfb1-017f6e4d435d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'* 앤드류 잭슨\\n* 웨인 그레츠키\\n* 짐 크로스비'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RunnableParallel을 사용하면 chain1의 결과와 chain2의 결과를 함께 얻을 수 있음"
      ],
      "metadata": {
        "id": "UKt8FoIgS1Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 때, chain1의 실행 결과를 chain2에 전달하는 방식으로 실행됨"
      ],
      "metadata": {
        "id": "DPQtnFvXS9r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate([\"잭슨빌은 어느 나라의 도시입니까?\"])\n",
        "prompt2 = ChatPromptTemplate([\"{country}의 대표적인 인물 3명을 나열하세요. 인물의 이름만 출력하세요.\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "chain2 = prompt2 | llm | StrOutputParser()\n",
        "\n",
        "chain3 = RunnableParallel(country = chain1).assign(people = chain2)\n",
        "chain3.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwRqPi8USyP4",
        "outputId": "1a5ed672-0316-48d8-aea3-71169b56c089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '잭슨빌은 **미국** 플로리다주에 있는 도시입니다.', 'people': '앤드류 잭슨, 웨인 그레츠키, 짐 크레인'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'잭슨빌은 **미국**의 도시입니다.'의 대표적인 인물 3명을 나열하세요. 인물의 이름만 출력하세요.가 전달되어 chain2 결과가 잘못 나옴"
      ],
      "metadata": {
        "id": "dmKTSrlnTwZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'나라 이름만 출력하세요'라고 추가"
      ],
      "metadata": {
        "id": "BdDMDXthTynA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate([\"잭슨빌은 어느 나라의 도시입니까? 나라 이름만 출력하세요.\"])\n",
        "prompt2 = ChatPromptTemplate([\"{country}의 대표적인 인물 3명을 나열하세요. 인물의 이름만 출력하세요.\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "chain2 = prompt2 | llm | StrOutputParser()\n",
        "\n",
        "chain3 = RunnableParallel(country = chain1).assign(people = chain2)\n",
        "chain3.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMh4sYmyTTk0",
        "outputId": "0a4fbdfe-2c55-4884-ea8c-fc0449119914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '미국', 'people': '아브라함 링컨\\n조지 워싱턴\\n마틴 루터 킹 주니어'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "chain2에서 새로운 매개변수가 추가되는 경우는 Lambda 함수를 통해 입력 Dict로부터 값을 선택"
      ],
      "metadata": {
        "id": "KJmtefWVUBVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate([\"{city}는 어느 나라의 도시인가요? 나라 이름만 출력하세요.\"])\n",
        "prompt2 = ChatPromptTemplate([\"{country}의 유명한 인물은 누가 있나요? {num}명의 이름을 출력하세요.\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "\n",
        "chain2 = (\n",
        "    RunnableParallel(country = chain1, num = lambda x:x['num'])\n",
        "    # lambda x:f(x) -> x가 주어지면 f(x)를 return\n",
        "    # invoke에서 주어지는 Dict를 전처리하기\n",
        "    | prompt2\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(chain2.invoke({\"city\": \"한국\", \"num\": \"10\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwbe4GndT6QR",
        "outputId": "2e4a20f1-17e6-4f93-92c4-2e17cfbe6d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국을 대표하는 유명 인물 10명은 다음과 같습니다.  이 목록은 다양한 분야의 인물을 포함하고 있으며,  선택 기준에 따라 다른 인물들이 포함될 수 있습니다.\n",
            "\n",
            "1. **세종대왕:** 조선 제4대 국왕, 훈민정음 창제 등 업적으로 유명.\n",
            "2. **김구:** 대한민국 임시정부 주석, 독립운동가.\n",
            "3. **윤동주:** 시인, 민족 시인으로 널리 알려짐.\n",
            "4. **김치하:** 소설가, <광장> 등의 작품으로 유명.\n",
            "5. **박찬호:** 메이저리그 야구 선수, 한국인 최초 메이저리거.\n",
            "6. **방시혁:** 프로듀서, 작곡가,  BTS의 성공에 큰 기여.\n",
            "7. **김연아:** 피겨 스케이팅 선수, 동계 올림픽 금메달리스트.\n",
            "8. **BTS (방탄소년단):**  글로벌 아이돌 그룹, 세계적인 인기를 얻음. (그룹 전체를 하나의 인물로 간주)\n",
            "9. **신사임당:** 조선 시대의 여류 화가, 서예가.\n",
            "10. **이순신:** 조선 시대의 명장, 임진왜란 당시 큰 공을 세움.\n",
            "\n",
            "\n",
            "이 외에도 수많은 유명 인물들이 있으니, 관심있는 분야에 따라 더 많은 정보를 찾아보시면 좋겠습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "체인을 분리하고 RunnableParallel을 이용하면 중간 과정을 모두 출력할 수 있음"
      ],
      "metadata": {
        "id": "aoOl1D_TVZe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain4 = (prompt2\n",
        "          | llm\n",
        "          | StrOutputParser())\n",
        "chain3 = RunnableParallel(country = chain1, num = lambda x:x['num']).assign(res=chain4)\n",
        "chain3.invoke({\"city\": \"부에노스 아이레스\", \"num\": \"3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxqdv_iAU_hm",
        "outputId": "348e6e36-0a0a-46ce-b079-7e69cfde4d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '아르헨티나',\n",
              " 'num': '3',\n",
              " 'res': '1. **리오넬 메시:** 세계적으로 유명한 축구 선수입니다.\\n2. **체 게바라:** 혁명가이자 의사였습니다.\\n3. **에바 페론:** 아르헨티나의 전직 제1부인이자 사회 운동가였습니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[연습문제] LangChain Expression Language  \n",
        "LLM을 3개 연결해서 3개 결과를 출력해보세요.  \n",
        "RunnableParallel.assign().assign() 형식을 고려하세요.  \n",
        "e.g.  \n",
        "1. 영화 입력 -> 감독 출력\n",
        "2. 감독 입력 -> 배우 출력\n",
        "3. 배우 입력 -> 입상 출력"
      ],
      "metadata": {
        "id": "bB33GhjYWBIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "prompt1 = ChatPromptTemplate([\"{movie}의 감독을 누구입니까? 감독 이름만 출력\"])\n",
        "prompt2 = ChatPromptTemplate([\"{director}와 작업한 가장 유명한 배우는 누구인가요? 배우 이름만 출력\"])\n",
        "prompt3 = ChatPromptTemplate([\"{actor}는 무슨 영화 출연으로 상을 받았나요?\"])\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "chain2 = prompt2 | llm | StrOutputParser()\n",
        "chain3 = prompt3 | llm | StrOutputParser()\n",
        "\n",
        "chain4 = RunnableParallel(director=chain1).assign(actor=chain2).assign(movie=chain3)\n",
        "chain4.invoke(\"파이트 클럽\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6g_-bNBVstQ",
        "outputId": "7303d1ea-bb0d-4238-d9d1-d792121595d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'director': '데이비드 핀처',\n",
              " 'actor': '브래드 피트',\n",
              " 'movie': '브래드 피트는 여러 영화로 상을 받았지만, 가장 주목할 만한 수상작은 다음과 같습니다.\\n\\n* **세븐 (1995):**  비록 주연은 아니었지만, 강렬한 연기로 많은 주목을 받았습니다.  하지만 세븐 자체로는 브래드 피트가 주요 상을 받았다고 보기는 어렵습니다.\\n\\n* **파이트 클럽 (1999):**  비평가들의 찬사를 받았지만, 주요 상 수상은 없었습니다.\\n\\n* **스내치 (2000):**  역시 주요 상 수상은 없었습니다.\\n\\n* **트로이 (2004):**  상업적으로 성공했지만, 개인적인 수상 경력에 큰 영향을 미치지는 않았습니다.\\n\\n* **바스터즈: 거친 녀석들 (2009):**  이 영화로 **아카데미 남우조연상**을 수상했습니다. 이는 그의 가장 큰 수상 업적으로 꼽힙니다.\\n\\n* **원스 어폰 어 타임 인 할리우드 (2019):**  이 영화로 **골든 글로브 남우조연상**을 수상했습니다.\\n\\n다른 작품들에서도 여러 후보 지명을 받았지만,  **아카데미 남우조연상 (바스터즈: 거친 녀석들)** 과 **골든 글로브 남우조연상 (원스 어폰 어 타임 인 할리우드)**이 가장 중요한 수상으로 여겨집니다.  그 외에도 여러 비평가협회상과 영화제에서 수상 또는 후보 지명이 있었습니다.  어떤 상에 초점을 맞추느냐에 따라 답이 달라질 수 있습니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}