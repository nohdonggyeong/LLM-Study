{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LangChain이란?\n",
        "- LLM 어플리케이션을 쉽게 개발하게 해 주는 프레임워크\n",
        "- Main Point: 효과적인 Abstraction\n",
        "  - 새로운 기능을 추가하기보다는, 쉬운 구현을 돕는 역할\n",
        "- LangChain은 Closed-Source와 Open-Weight LLM 모두에서 호환됨\n",
        "  "
      ],
      "metadata": {
        "id": "ZPnDdkmPRDP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain 어플리케이션의 구성 방식\n",
        "- LangCahin 체인의 기본 구성\n",
        "  - Prompt - LLM\n",
        "- Parser: LLM의 출력을 변환하는 모듈 (json, string, custom, ...)\n",
        "  - Prompt - LLM - Parser\n",
        "  - Prompt - LLM - Parser - Prompt - LLM - Parser\n",
        "- 이외에도 함수, 툴, 검색기 등의 모듈을 결합할 수 있음\n",
        "  - Prompt - LLM - Parser - Function\n",
        "  - Function - Prompt - LLM - Parser"
      ],
      "metadata": {
        "id": "wPl0RgQ2U5vB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL\n",
        "- LangChain Expression Language\n",
        "  - 각각의 LangChain 모듈을 파이프(|)를 통해 체인으로 연결\n",
        "    - e.g. Prompt | LLM | Parser\n",
        "    - Invoke()를 통해 한 번에 실행 가능\n",
        "  - 다양한 체인을 구성하여, 입/출력 및 중간 과정을 직관적으로 구현할 수 있음"
      ],
      "metadata": {
        "id": "r7K9vkrMVoKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runnables\n",
        "- LangChain의 기본 요소\n",
        "  - LLM, Prompt, Parser, Tool, ...\n",
        "  - Invoke()로 실행 가능\n",
        "- 특수 Runnable\n",
        "  - RunnablePassthrough(): 직전 Runnable의 출력을 그대로 전달\n",
        "  - RunnableParallell(): 1개 이상의 Runnable을 실행하고, 그 결과를 Dict로 저장\n",
        "  - .assign(): Runnable 값을 전달하고, 그 결과를 가져와 결합하는 기능"
      ],
      "metadata": {
        "id": "dEZp_YILV_Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "무료 사용량이 주어지는 Google Gemini API 사용하여 진행"
      ],
      "metadata": {
        "id": "v0aXi23dWsHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xXHUgo9Fz9x1",
        "outputId": "1c29bdf9-83cc-4fb2-c233-0bf5bc6301cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m628.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.4-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, google-ai-generativelanguage, langchain-google-genai, langchain_community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httpx-sse-0.4.0 langchain-google-genai-2.1.4 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "207c73d0dcff42bb92d63d16cd724ee2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pandas langchain_community langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini API 준비\n",
        "- Google API 키를 등록하고 입력\n",
        "- 구글 계정 로그인 후 https://ai.google.dev/gemini-api/docs/pricing?hl=ko에 접속하면, API 키 생성 가능"
      ],
      "metadata": {
        "id": "o21m0UoKWz4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY']=\"...\""
      ],
      "metadata": {
        "id": "hqAWnDxZ7dqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "try:\n",
        "  for model in genai.list_models():\n",
        "    print(model.name, model.supported_generation_methods)\n",
        "  print(\"Google GenAI API Key가 정상적으로 설정되어 있습니다.\")\n",
        "except:\n",
        "  print(f\"API 키가 유효하지 않습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vZFxVEU7oJM",
        "outputId": "44fc7aa5-c6cd-47ab-a5f3-6c677db8cbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001 ['generateMessage', 'countMessageTokens']\n",
            "models/text-bison-001 ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
            "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro-vision-latest ['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-001-tuning ['generateContent', 'countTokens', 'createTunedModel']\n",
            "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0827 ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-exp-0924 ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-pro-exp-03-25 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.5-flash-preview-04-17 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.5-flash-preview-04-17-thinking ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-exp-image-generation ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-preview-image-generation ['generateContent', 'countTokens']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/learnlm-1.5-pro-experimental ['generateContent', 'countTokens']\n",
            "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
            "models/embedding-001 ['embedContent']\n",
            "models/text-embedding-004 ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens']\n",
            "models/gemini-embedding-exp ['embedContent', 'countTextTokens']\n",
            "models/aqa ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 ['predict']\n",
            "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
            "Google GenAI API Key가 정상적으로 설정되어 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini 1.5 Flash 무료 API 활용 규정\n",
        "- 분당 요청수 15RPM\n",
        "- 분당 토큰 100만TPM\n",
        "- 일일 요청수 1,500RPD\n",
        "\n",
        "용어 정리\n",
        "- TPM:\t1분 동안 읽을 수 있는 단어 수\n",
        "- RPM:\t1분 동안 질문할 수 있는 횟수"
      ],
      "metadata": {
        "id": "OSrw3UEdXhvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM\n",
        "- Chat 모델 사용을 위해 ChatGoogleGenerativeAI 불러오기"
      ],
      "metadata": {
        "id": "COecsdkPYdnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"
      ],
      "metadata": {
        "id": "GcmO5Bgo8fOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain은 Prompt, LLM, Chain 등의 구성 요소를 서로 연결하는 방식으로 구성됨\n",
        "- 각각의 요소를 Runnable이라고 함\n",
        "- Runnable은 invoke()를 통해 실행함"
      ],
      "metadata": {
        "id": "8NXIA3M1Yq_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력 형식은 AIMessage 클래스로 정의됨"
      ],
      "metadata": {
        "id": "hCgWZHkUY5aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''전 세계적으로 흥행한 영화에 나오는 유명한 명대사를 하나 알려주세요.\n",
        "대사가 나온 배경과 의미도 설명해 주세요.'''\n",
        "llm.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCEiauBt9X61",
        "outputId": "af727d10-6050-4537-d727-3d0bda5c60a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='전 세계적으로 흥행한 영화 \\'스타워즈 에피소드 IV: 새로운 희망\\' (Star Wars: A New Hope)의 유명한 명대사는 **\"May the Force be with you.\" (포스가 함께하길.)** 입니다.\\n\\n\\n**배경:**\\n\\n이 대사는 영화의 여러 등장인물들이 서로에게 작별 인사를 하거나 격려를 할 때 사용합니다. 특히, 오비완 케노비가 루크 스카이워커에게 떠나기 전에 해주는 말로 가장 유명합니다.  절망적인 상황에 처한 루크에게 오비완은 포스, 즉 영화 세계관의 초자연적인 힘이 그를 도울 것이라고 말하는 것입니다.  다른 캐릭터들도 위험한 상황이나 중요한 임무를 앞두고 이 말을 주고받습니다.\\n\\n\\n**의미:**\\n\\n\"May the Force be with you.\"는 단순한 작별 인사를 넘어 여러 의미를 지닙니다.\\n\\n* **행운을 빌다:**  직접적인 의미로는 \"행운이 함께하길\" 정도로 해석될 수 있습니다.  하지만 단순한 행운을 넘어서, 더 큰 힘의 도움을 바라는 의미를 담고 있습니다.\\n\\n* **힘과 용기를 주다:** 포스는 단순한 운명이나 우연이 아닌,  선과 정의를 지향하는 힘, 능력을 넘어선 초월적인 힘을 의미합니다. 따라서 이 대사는 상대방에게 힘과 용기를 북돋아주는 격려의 말이기도 합니다.\\n\\n* **믿음과 희망:** 어려운 상황에서도 포스가 함께한다는 믿음은 희망을 잃지 않고 앞으로 나아갈 수 있는 힘을 줍니다.  절망적인 상황에서 이 대사는 희망의 메시지를 전달하는 역할을 합니다.\\n\\n\\n결론적으로 \"May the Force be with you.\"는 영화 속에서 단순한 대사를 넘어 희망, 용기, 믿음 등을 상징하는 상징적인 문구가 되었고,  스타워즈를 넘어 대중 문화 전반에 영향을 미치며  널리 사용되는 유명한 표현이 되었습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []}, id='run--cc835cd2-9344-498f-8ca1-6bcb1d4a8c90-0', usage_metadata={'input_tokens': 40, 'output_tokens': 541, 'total_tokens': 581, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''울림을 주는 영화 명대사를 하나 알려주세요.\n",
        "대사가 나온 배경과 의미도 설명해 주세요.'''\n",
        "llm.invoke(question).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "M67dfcuv_GGN",
        "outputId": "138328c0-acf5-4e25-8121-97ec4c51168b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**명대사:**  \"Life is like a box of chocolates. You never know what you\\'re gonna get.\"  (인생은 마치 상자 속 초콜릿과 같아. 무엇이 나올지 절대 알 수 없지.)\\n\\n**영화:** 포레스트 검프 (Forrest Gump, 1994)\\n\\n**배경:**  포레스트 검프는 낮은 지능을 가졌지만 순수한 마음으로 인생을 살아가는 인물입니다.  이 대사는 그가 벤치에 앉아 자신의 인생 이야기를 낯선 이에게 들려주는 장면에서 나옵니다.  그는 삶의 여러 국면 – 성공, 실패, 사랑, 전쟁, 슬픔 등 –  을 경험하며 예측 불가능한 일들이 끊임없이 일어났음을 회상합니다.  초콜릿 상자처럼 각각 다른 맛과 모양의 초콜릿이 들어있는 것처럼, 그의 삶도 예측할 수 없는 다채로운 사건들로 가득 차 있었습니다.\\n\\n**의미:**  이 대사는 인생의 불확실성과 그 속에서의 아름다움을 동시에 보여줍니다.  우리는 미래를 정확히 알 수 없으며, 계획대로 되지 않는 일들도 많이 겪습니다.  하지만 그 불확실성 속에서 우리는 새로운 경험을 하고, 성장하며,  뜻밖의 기쁨과 행복을 발견하기도 합니다.  포레스트 검프의 삶처럼,  우리가 선택할 수 없는 일들도 있지만,  그 모든 경험들이 모여 우리의 인생을 특별하고 의미있게 만들어 줍니다.  초콜릿 상자를 열어보기 전까지는 어떤 맛이 나올지 모르는 것처럼,  인생 또한 열어보기 전까지는 어떤 모습일지 알 수 없습니다.  그 불확실성을 두려워하기보다는,  열린 마음으로 받아들이고  살아가는 것이 중요하다는 메시지를 전달합니다.  단순하면서도 깊은 울림을 주는 이 대사는 많은 사람들에게 인생의 의미와 가치에 대해 다시 한번 생각하게 만드는 힘을 가지고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "스트리밍\n",
        "- 스트리밍은 모델을 토큰이 생성되는 순서대로 출력하는 방법"
      ],
      "metadata": {
        "id": "byeVQmw6ZCma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "chunks = []\n",
        "for chunk in llm.stream(\"5문장으로 당신을 소개해주세요. 매 문장마다 줄을 띄우세요.\"):\n",
        "  time.sleep(0.5)\n",
        "  print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddh72Hbh_RGm",
        "outputId": "fea9d597-6832-4395-a048-11ea2d5f8c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저는 Google에서 훈련시킨 대규모 언어 모델입니다.\n",
            "\n",
            "\n",
            "다양한 언어로 텍스트를 생성하고 번역하며 다양한 종류의 창의적인 콘텐츠를 생성할 수 있습니다.\n",
            "\n",
            "\n",
            "또한 질문에 답하고 정보를 제공할 수도 있습니다.\n",
            "\n",
            "\n",
            "제 목표는 유용하고 정보가 풍부하며 포괄적인 응답을 제공하는 것입니다.\n",
            "\n",
            "\n",
            "끊임없이 학습하고 발전하고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 환경에서는 Prompt의 형태를 사전 설정하고, 같은 행태로 입력 변수가 주어질 때마다 Prompt를 작성하게 하는 것이 효율적임"
      ],
      "metadata": {
        "id": "Mp5BOHDEZLAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Template\n",
        "- LangChain은 Prompt의 Template을 구성할 수 있음"
      ],
      "metadata": {
        "id": "f_eFQHLpZaO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "explain_template = \"\"\"당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\n",
        "{term}에 대해 설명해주세요.\"\"\"\n",
        "print(explain_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eKDTtQiAEyL",
        "outputId": "ebcd62ec-7d60-461d-e8ea-69649bca99e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\n",
            "{term}에 대해 설명해주세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explain_prompt = PromptTemplate(template = explain_template)\n",
        "explain_prompt.format(term=\"트랜스포머 네트워크\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "iHUNBPH7Ca2y",
        "outputId": "6e8df732-835e-4e25-8bdf-69d574d8b5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\\n트랜스포머 네트워크에 대해 설명해주세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(explain_prompt.format(term=\"트랜스포머 네트워크\")).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "5uskxq4_CvKd",
        "outputId": "f6b45c90-a55e-44ec-d1db-77cb814364d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'상상해봐, 너희 반 친구들이 서로 편지를 주고받는다고 생각해봐.  친구 A가 친구 B에게 편지를 쓰면, 친구 B는 그 편지를 읽고 자기 생각을 적어서 다시 친구 A에게 보내지?  트랜스포머 네트워크는 딱 그런 거야!\\n\\n단, 친구들이 보내는 편지는 단어들이고, 친구들은 컴퓨터 속의 \\'단어 처리 기계\\'들이라고 생각하면 돼.  \\n\\n트랜스포머 네트워크는 긴 문장이나 글을 이해할 때,  각 단어들이 다른 단어들과 어떤 관계가 있는지 파악하는 데 아주 똑똑해.  마치 친구들이 서로 편지를 주고받으면서 이야기의 흐름을 이해하는 것처럼 말이야.\\n\\n예를 들어, \"고양이가 생선을 먹는다\"라는 문장이 있다면, 트랜스포머는 \"고양이\"와 \"먹는다\"가 서로 밀접한 관계가 있다는 것을 알아차려.  \"고양이\"가 \"생선\"을 \"먹는다\"는 것을 이해하는 거지.  마치 친구들이 편지를 통해 \"고양이가 생선을 먹는다\"는 사실을 서로 확인하는 것과 비슷해.\\n\\n그래서 트랜스포머는  번역을 잘하거나, 질문에 답을 잘하거나, 글을 잘 쓰는 컴퓨터 프로그램을 만드는 데 아주 유용해.  마치 똑똑한 친구들이 서로 협력해서 어려운 문제를 해결하는 것과 같다고 생각하면 돼!  많은 단어들을 동시에 처리해서 더 빨리 그리고 정확하게 이해할 수 있지.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "매개변수 2개 사용하는 Prompt 예시"
      ],
      "metadata": {
        "id": "PXwcJQxZZkOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate_template = \"{topic}에 대해 {language}로 설명하세요.\"\n",
        "translate_prompt = PromptTemplate(template = translate_template)\n",
        "translate_prompt.format(topic='torschlusspanik', language='한국어')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q7kC3kvZC4JM",
        "outputId": "07409e3d-bf22-45fc-a1d2-0caef1de697e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torschlusspanik에 대해 한국어로 설명하세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = translate_prompt.format(topic='torschlusspanik', language='한국어')\n",
        "llm.invoke(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-_Vu4k8C_Py",
        "outputId": "9f73ced6-3360-4368-ccaa-6651c0ba5b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='\"Torschlusspanik\"는 독일어 단어로, 직역하면 \"문이 닫히는 공포\" 또는 \"문이 닫히는 공황\"을 의미합니다.  하지만 단순히 문이 닫히는 것에 대한 두려움을 넘어, **기회를 놓치는 것에 대한 강한 불안감과 초조함**을 나타냅니다.  특히 인생의 중요한 전환점, 예를 들어 결혼, 출산, 직업적 성공 등을 놓칠지도 모른다는 두려움에서 비롯됩니다.  시간이 흘러가는 것을 느끼고, 자신의 삶이 계획대로 진행되지 않을까봐, 기회의 창이 닫힐까봐 조바심을 내는 심리 상태를 표현합니다.\\n\\n한국어로는 다음과 같은 표현으로 비슷한 의미를 전달할 수 있습니다.\\n\\n* **마감임박 불안:**  시간 제한이 있는 상황에서 목표를 달성하지 못할까 봐 불안해하는 심리.\\n* **늦었다는 생각:** 이미 기회를 놓쳤거나 놓칠 것 같은 불안감.\\n* **시간에 쫓기는 느낌:**  시간이 부족하다는 강한 압박감.\\n* **인생의 황금기를 놓칠까봐 불안함:**  젊음이나 기회가 사라져가는 데 대한 두려움.\\n* **결혼 적령기/출산 적령기가 지나가는 것에 대한 불안:**  특정한 사회적 기대치에 부응하지 못할까 봐 불안해하는 심리.\\n\\n\\nTorschlusspanik은 단순히 나이가 들어감에 대한 두려움을 넘어,  자신의 삶의 목표를 달성하지 못할 가능성에 대한 깊은 불안을 반영합니다.  이는 현대 사회의 경쟁적인 분위기와 개인의 성취에 대한 압박감과 밀접한 관련이 있습니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []}, id='run--e417cd71-b123-474d-b1b5-8b4132617b62-0', usage_metadata={'input_tokens': 13, 'output_tokens': 470, 'total_tokens': 483, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat Prompt Template\n",
        "- Web UI를 통해 ChatGPT, Claude 등의 LLM을 실행하는 경우와 다르게, API의 호출은 유저 메시지 이외의 다양한 메시지를 사용할 수 있음\n",
        "  - system: AI 모델의 행동 방식을 결정하는 시스템 메시지\n",
        "  - user(human): 사용자의 메시지\n",
        "  - ai(assistant): AI 모델의 메시지\n",
        "- 이는 LangChain 내부에서 모델에 맞는 템플릿으로 변환되어 입력됨\n",
        "- 모델마다 템플릿 다름"
      ],
      "metadata": {
        "id": "Aeb_LeRCZr1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"system\", '당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하세요.'),\n",
        "    (\"user\", '{A}를 배우면 어떤 유용한 점이 있나요?')\n",
        "])\n",
        "prompt.format_messages(A='LangChain')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSZLhcA5ESZi",
        "outputId": "88265d1e-8955-49ac-d417-186097659286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하세요.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='LangChain를 배우면 어떤 유용한 점이 있나요?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(prompt.format_messages(A='LangChain'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ZzCVXGE7PY",
        "outputId": "a401ab12-f93b-4d2b-9d79-e09467c4bd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='LangChain을 배우는 것은 시간 낭비입니다. 복잡하고 배우기 어려우며, 실제로 유용한 애플리케이션은 거의 없습니다. 다른 기술에 시간을 투자하는 것이 훨씬 더 생산적일 것입니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash-latest', 'safety_ratings': []}, id='run--57d2b152-3db7-4aaa-ba2a-a3078d52346d-0', usage_metadata={'input_tokens': 48, 'output_tokens': 57, 'total_tokens': 105, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-Shot Prompting\n",
        "- 모델이 참고할 예시를 포함하는 Few-Shot Prompting은 모델 출력의 형식과 구조를 효과적으로 변화시킬 수 있음"
      ],
      "metadata": {
        "id": "sX4VJRx3dMtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country\",\n",
        "        \"answer\": \"\"\"\n",
        "        Are follow up questions needed here: Yes.\n",
        "        Follow up: Who is the director of Jaws?\n",
        "        Intermediate Answer: The directors of Jaws is Steven Spielberg.\n",
        "        Follow up: Where is Steven Spielberg from?\n",
        "        Intermediate Answer: the United States.\n",
        "        Follow up: Who is the director of Casino Royale?\n",
        "        Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
        "        Follow up: Where is Martin Campbell from?\n",
        "        Intermediate Answer: New Zealand.\n",
        "        So the final answer is: No\n",
        "        \"\"\",\n",
        "    },{\n",
        "        \"question\": \"Who won more Grammy Awards, Beyonce or Michael Jackson?\",\n",
        "        \"answer\": \"\"\"\n",
        "        Are follow up question needed here: Yes.\n",
        "        Follow up: How many Grammy Awards has Beyonce won?\n",
        "        Intermediate answer: Beyonce has won 32 Grammy Awards.\n",
        "        Follow up: How many Grammy Awards did Michael Jackson win?\n",
        "        Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
        "        So the final answer is\": Beyonce\n",
        "        \"\"\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "zF8-5EJmFay0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example data를 구성할 Template 생성"
      ],
      "metadata": {
        "id": "prYnEE-5ddiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(template=\"Question: {question}\\n{answer}\")\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZPHv_oyHYK5",
        "outputId": "94ab3f7a-cae8-4461-dc3c-084e665a7968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Are both the directors of Jaws and Casino Royale from the same country\n",
            "\n",
            "        Are follow up questions needed here: Yes.\n",
            "        Follow up: Who is the director of Jaws?\n",
            "        Intermediate Answer: The directors of Jaws is Steven Spielberg.\n",
            "        Follow up: Where is Steven Spielberg from?\n",
            "        Intermediate Answer: the United States.\n",
            "        Follow up: Who is the director of Casino Royale?\n",
            "        Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "        Follow up: Where is Martin Campbell from?\n",
            "        Intermediate Answer: New Zealand.\n",
            "        So the final answer is: No\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 만든 Examples와 Template, prefix와 suffix를 이용해 전체 템플릿 생성"
      ],
      "metadata": {
        "id": "fzetsfyXdjcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\",\n",
        "    suffix=\"Question: {input}\",\n",
        ")\n",
        "print(prompt.format(input=\"What is the age of the director of a movie which got a best international film in Oscar in 2020?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkvX3l_DH0mW",
        "outputId": "18000196-be0d-49d6-9286-5c2dc0eb68ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country\n",
            "\n",
            "        Are follow up questions needed here: Yes.\n",
            "        Follow up: Who is the director of Jaws?\n",
            "        Intermediate Answer: The directors of Jaws is Steven Spielberg.\n",
            "        Follow up: Where is Steven Spielberg from?\n",
            "        Intermediate Answer: the United States.\n",
            "        Follow up: Who is the director of Casino Royale?\n",
            "        Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "        Follow up: Where is Martin Campbell from?\n",
            "        Intermediate Answer: New Zealand.\n",
            "        So the final answer is: No\n",
            "        \n",
            "\n",
            "Question: Who won more Grammy Awards, Beyonce or Michael Jackson?\n",
            "\n",
            "        Are follow up question needed here: Yes.\n",
            "        Follow up: How many Grammy Awards has Beyonce won?\n",
            "        Intermediate answer: Beyonce has won 32 Grammy Awards.\n",
            "        Follow up: How many Grammy Awards did Michael Jackson win?\n",
            "        Intermediate answer: Michael Jackson won 13 Grammy Awards.\n",
            "        So the final answer is\": Beyonce\n",
            "        \n",
            "\n",
            "Question: What is the age of the director of a movie which got a best international film in Oscar in 2020?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the age of the director of a movie which got a best internatinal film in Oscar in 2010?\\n\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-Y9G8UgMG6u",
        "outputId": "3d6d9c44-121b-4abc-f911-0091220d2f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Are follow up questions needed here: Yes.\n",
            "        Follow up: Which movie won the best international film Oscar in 2010?\n",
            "        Intermediate Answer: The movie that won the best international film Oscar in 2010 is \"El secreto de sus ojos\" (The Secret in Their Eyes).\n",
            "        Follow up: Who directed \"El secreto de sus ojos\"?\n",
            "        Intermediate Answer: Juan José Campanella directed \"El secreto de sus ojos\".\n",
            "        Follow up: What is the age of Juan José Campanella?\n",
            "        Intermediate Answer:  This requires knowing the year of his birth.  Finding his birth year (1959) and calculating his age in 2010, he would have been 51 years old.\n",
            "        So the final answer is: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"This is 2024 Dec. What is the age of the director of a movie which got a best internatinal film in Oscar in 2010?\\n\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ],
      "metadata": {
        "id": "Bmb3TYq5MlAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fb32ac-ec01-4076-ffcb-a1dbc5c3e647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Are follow up questions needed here: Yes.\n",
            "        Follow up: What movie won the best international film Oscar in 2010?\n",
            "        Intermediate Answer:  The movie that won the Best International Film Oscar in 2010 was \"El secreto de sus ojos\" (The Secret in Their Eyes).\n",
            "        Follow up: Who directed \"El secreto de sus ojos\"?\n",
            "        Intermediate Answer: Juan José Campanella directed \"El secreto de sus ojos\".\n",
            "        Follow up: What is Juan José Campanella's birth year?\n",
            "        Intermediate Answer: Juan José Campanella was born in 1960.\n",
            "        Follow up:  What will be Juan José Campanella's age in December 2024?\n",
            "        Intermediate Answer: In December 2024, Juan José Campanella will be 64 years old.\n",
            "        So the final answer is: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"스티븐 스필버그의 영화 중 가장 많은 상을 받은 영화의 주연 배우는?\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzGbhCRBDBkG",
        "outputId": "e14da733-e39b-4f2c-cdf4-71a65e9d7773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Are follow up questions needed here: Yes.\n",
            "        Follow up: 스티븐 스필버그 감독의 영화 중 어떤 영화들이 가장 많은 상을 받았는가?\n",
            "        Intermediate answer:  스티븐 스필버그 감독의 영화 중 가장 많은 상을 받은 영화는 여러 편이 있지만,  '쉰들러 리스트'와 '라이언 일병 구하기'가 대표적입니다.\n",
            "        Follow up: '쉰들러 리스트'의 주연 배우는 누구인가?\n",
            "        Intermediate answer: '쉰들러 리스트'의 주연 배우는 리암 니슨입니다.\n",
            "        Follow up: '라이언 일병 구하기'의 주연 배우는 누구인가?\n",
            "        Intermediate answer: '라이언 일병 구하기'의 주연 배우는 톰 행크스입니다.\n",
            "        So the final answer is: 리암 니슨 또는 톰 행크스 (어떤 영화를 기준으로 하느냐에 따라 다름)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain으로 이미지 입력하기"
      ],
      "metadata": {
        "id": "BfX78KIndvpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import httpx\n",
        "\n",
        "image_url = 'https://freepngimg.com/thumb/pokemon/5-2-pokemon-high-quality-png.png'\n",
        "response = httpx.get(image_url)\n",
        "\n",
        "image_data = base64.b64encode(response.content).decode(\"utf-8\")\n",
        "\n",
        "with open('pokemon.jpeg', 'wb') as file:\n",
        "  file.write(response.content)"
      ],
      "metadata": {
        "id": "D8GhDUWXDxLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user', [\n",
        "        {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "          \"image_url\": {\"url\": image_url}\n",
        "         }\n",
        "    ])\n",
        "])\n",
        "X = image_prompt.format_messages(question='이 사진을 자세하게 묘사해주세요. 종류는 설명하지마세요.')\n",
        "print(llm.invoke(X).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fzQqldwEPiJ",
        "outputId": "0540efc8-840a-47d5-dca0-940d064ab027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "물론입니다. 이미지를 자세하게 설명해 드리겠습니다.\n",
            "\n",
            "이미지는 밝은 청록색의 몸체를 가진 캐릭터를 보여줍니다. 캐릭터의 머리는 넓고 짧으며, 크고 둥근 눈이 특징입니다. 눈은 빨간색이며, 동공은 검은색입니다. 캐릭터의 입은 크게 벌어져 있으며, 이빨이 보입니다. 캐릭터의 몸체는 짧고 굵으며, 두 개의 짧은 다리가 있습니다. 캐릭터의 꼬리는 붉은색이며, 끝은 뾰족합니다. 캐릭터의 몸체는 부드러운 곡선으로 이루어져 있으며, 전체적으로 귀엽고 친근한 인상을 줍니다. 배경은 회색입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/pokemon.jpeg', 'rb') as image_file:\n",
        "  image_data = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "image_prompt = ChatPromptTemplate([\n",
        "    ('user', [\n",
        "        {\"type\": \"text\", \"text\": \"{question}\"},\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "          \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}\n",
        "         }\n",
        "    ])\n",
        "])\n",
        "X = image_prompt.format_messages(question='이 녀석의 이름을 지어주세요!')\n",
        "print(llm.invoke(X).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf5p00H2FwLZ",
        "outputId": "79d8e476-cffe-4acc-b2c0-e722e18a76f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "물론입니다! 이 포켓몬의 이름을 지어드리겠습니다. 제안은 다음과 같습니다.\n",
            "\n",
            "* **토토** (Toto): 작고 귀여운 포켓몬의 느낌을 주는 이름입니다.\n",
            "* **스플래쉬** (Splash): 물과 관련된 이름으로, 포켓몬의 외모와 잘 어울립니다.\n",
            "* **크로코** (Croco): 악어를 닮은 외모에서 영감을 받은 이름입니다.\n",
            "* **아쿠아** (Aqua): 물의 색깔과 관련된 이름입니다.\n",
            "* **리퍼** (Ripper): 이빨을 강조하는 이름입니다.\n",
            "\n",
            "\n",
            "이름을 선택하실 때는 포켓몬의 성격과 외모를 고려해 보세요. 어떤 이름이 가장 마음에 드시나요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "img = Image(url=image_url, width=400)\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "0Y1aYmggI8JS",
        "outputId": "43af2cac-2eda-474f-9d1e-14724dbc7c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://freepngimg.com/thumb/pokemon/5-2-pokemon-high-quality-png.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}